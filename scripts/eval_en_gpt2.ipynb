{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import torch.nn.functional as F\n",
    "import dictionary_corpus\n",
    "from torch.autograd import Variable\n",
    "from collections import defaultdict\n",
    "\n",
    "import transformers\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model file\n",
    "fn = \"../../GPT2Wiki/models/ptorch/state-9-193.pt\" # Change!\n",
    "model_name = \"GPT2-Wikipedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.AutoConfig.from_pretrained(\"../../GPT2Wiki/models/checkpoints/\")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "state_dict = torch.load(fn, map_location=torch.device('cpu'))[\"model\"]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data files\n",
    "data_path = \"../../GPT2Wiki/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dictionary_corpus.Dictionary(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vocab(word_list):\n",
    "    \"\"\"\n",
    "    Check if elements from word_list are in the model's vocab\n",
    "    \"\"\"\n",
    "    unknown = set()\n",
    "    for w in word_list:\n",
    "        try:\n",
    "            idx = dictionary.word2idx[w]\n",
    "        except KeyError:\n",
    "            unknown.add(w)\n",
    "    print(unknown)\n",
    "    print(len(unknown), \"word(s) is/are not in the model's vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_surprisal(prompt):\n",
    "    \"\"\"\n",
    "    Assigns surprisal values to a sentence\n",
    "    prompt: list with sentence tokens\n",
    "    Returns a list with surprisal values for the sentence\n",
    "    \"\"\"\n",
    "    # Sent has <bos> and <eos> tokens for which surprisal of 0 is assigned\n",
    "    surprisal_arr = [0]  # surprisal for <bos> token already added\n",
    "    indices = [dictionary.word2idx[w] if w in dictionary.word2idx\n",
    "               else dictionary.word2idx[\"<unk>\"]\n",
    "               for w in prompt]\n",
    "    indices = torch.tensor(indices, dtype=torch.long)\n",
    "    output = model(indices.view(-1, 1)).logits  # one input at a time, thus batch_size = 1\n",
    "    for position, next_word in enumerate(prompt[1:-1]):  # excluding actual surprisal for <bos> and <eos>\n",
    "        current_word_scores = output[position].view(-1)  # the output vector corresponding to the current word\n",
    "        current_word_probs = F.log_softmax(current_word_scores, dim=0) # (log) softmax the score to get probabilities\n",
    "        next_word_prob = current_word_probs[dictionary.word2idx[next_word]] # get the prob of the true next word\n",
    "        surprisal = next_word_prob*(-1) \n",
    "        surprisal_arr.append(surprisal.item())\n",
    "    surprisal_arr.append(0)  # surprisal for <eos> \n",
    "    return surprisal_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surprisal_values(data):\n",
    "    \"\"\"\n",
    "    Get surprisal values for a 'word' column in a df\n",
    "    Returns a list with surprisal values for the whole df\n",
    "    \"\"\"\n",
    "    surprisal_values = []\n",
    "    end_idx = data.loc[data['word'] == '<eos>'].index.to_list()  # list with idx of rows that contain <eos>\n",
    "    end_idx = [-1,*end_idx]  # inserting -1 as the start index to get the first sentence right\n",
    "    for i in range(len(end_idx)-1):\n",
    "        sent_range = range(end_idx[i]+1, end_idx[i+1]+1)\n",
    "        sent_words = data.iloc[sent_range]['word'].to_list()\n",
    "        surprisal_arr = sent_surprisal(sent_words)\n",
    "        for s in surprisal_arr:\n",
    "            surprisal_values.append(s)\n",
    "    return surprisal_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Get output filename from input filename by adding \"_result\"\n",
    "    \"\"\"\n",
    "    result_filename = '../data/results/gpt2/' + os.path.basename(dataset)[:-4] + '_result.csv' \n",
    "    print(result_filename)\n",
    "    return result_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(dataset):\n",
    "    words = []\n",
    "    data = read_csv(dataset, index_col=0)\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"word\"] != \"<bos>\":\n",
    "            words.append(row[\"word\"])\n",
    "    check_vocab(words)\n",
    "    surprisal_values = get_surprisal_values(data)\n",
    "    data[\"surprisal\"] = surprisal_values\n",
    "    data[\"dependency\"] = \"Wh\"\n",
    "    data[\"language\"] = \"English\"\n",
    "    result_fn = filename_from_dataset(dataset)\n",
    "    data.to_csv(result_fn, encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "0 word(s) is/are not in the model's vocabulary\n",
      "../data/results/gpt2/eq_wh_en_result.csv\n",
      "set()\n",
      "0 word(s) is/are not in the model's vocabulary\n",
      "../data/results/gpt2/whether_wh_en_result.csv\n",
      "set()\n",
      "0 word(s) is/are not in the model's vocabulary\n",
      "../data/results/gpt2/subject_wh_en_result.csv\n",
      "set()\n",
      "0 word(s) is/are not in the model's vocabulary\n",
      "../data/results/gpt2/unbound_wh_en_result.csv\n"
     ]
    }
   ],
   "source": [
    "analyze_data('../data/test_sentences/eq_wh_en.csv')\n",
    "analyze_data('../data/test_sentences/whether_wh_en.csv')\n",
    "analyze_data('../data/test_sentences/subject_wh_en.csv')\n",
    "analyze_data('../data/test_sentences/unbound_wh_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
